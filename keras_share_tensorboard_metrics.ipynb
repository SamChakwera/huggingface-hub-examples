{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-share-tensorboard-metrics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmSXjNQg+e7ep2VDTnQXo4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nateraw/huggingface-hub-examples/blob/main/keras_share_tensorboard_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3G09mlaF4Mt"
      },
      "source": [
        "%%capture\n",
        "! pip install git+https://github.com/huggingface/huggingface_hub.git@main\n",
        "! sudo apt -qq install git-lfs\n",
        "! git config --global credential.helper store"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUZWRnP4Jfef"
      },
      "source": [
        "## Make sure you're logged in to Hugging Face CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8pDwbNJe4F"
      },
      "source": [
        "! huggingface-cli login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcuLdv9PJE0T"
      },
      "source": [
        "# Simple Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I90IsKHqJu-J"
      },
      "source": [
        "# Complete Example\n",
        "\n",
        "This is a more complete example of training a denoising autoencoder (taken from [keras-io/examples](https://github.com/keras-team/keras-io/blob/master/examples/vision/autoencoder.py))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_8MBueYGBmj"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm4X6gFgHC66"
      },
      "source": [
        "def preprocess(array):\n",
        "    \"\"\"\n",
        "    Normalizes the supplied array and reshapes it into the appropriate format.\n",
        "    \"\"\"\n",
        "\n",
        "    array = array.astype(\"float32\") / 255.0\n",
        "    array = np.reshape(array, (len(array), 28, 28, 1))\n",
        "    return array\n",
        "\n",
        "\n",
        "def noise(array):\n",
        "    \"\"\"\n",
        "    Adds random noise to each image in the supplied array.\n",
        "    \"\"\"\n",
        "\n",
        "    noise_factor = 0.4\n",
        "    noisy_array = array + noise_factor * np.random.normal(\n",
        "        loc=0.0, scale=1.0, size=array.shape\n",
        "    )\n",
        "\n",
        "    return np.clip(noisy_array, 0.0, 1.0)\n",
        "\n",
        "\n",
        "def display(array1, array2):\n",
        "    \"\"\"\n",
        "    Displays ten random images from each one of the supplied arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    n = 10\n",
        "\n",
        "    indices = np.random.randint(len(array1), size=n)\n",
        "    images1 = array1[indices, :]\n",
        "    images2 = array2[indices, :]\n",
        "\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(image1.reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(image2.reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoS4NeP7HF32"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj6X74kcHFil"
      },
      "source": [
        "# Since we only need images from the dataset to encode and decode, we\n",
        "# won't use the labels.\n",
        "(train_data, _), (test_data, _) = mnist.load_data()\n",
        "\n",
        "# Normalize and reshape the data\n",
        "train_data = preprocess(train_data)\n",
        "test_data = preprocess(test_data)\n",
        "\n",
        "# Create a copy of the data with added noise\n",
        "noisy_train_data = noise(train_data)\n",
        "noisy_test_data = noise(test_data)\n",
        "\n",
        "# Display the train data and a version of it with added noise\n",
        "display(train_data, noisy_train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFSZIVe5HJmm"
      },
      "source": [
        "## Build the Autoencoder\n",
        "\n",
        "We are going to use the Functional API to build our convolutional autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avlOaWBbHPAI"
      },
      "source": [
        "input = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "# Encoder\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
        "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "\n",
        "# Decoder\n",
        "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "# Autoencoder\n",
        "autoencoder = Model(input, x)\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVZh9PRLHcIV"
      },
      "source": [
        "## Train the Autoencoder on Noisy Data\n",
        "\n",
        "We want our autoencoder to learn how to denoise the images."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir='logs')"
      ],
      "metadata": {
        "id": "8pMs-0pe2IJM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUn1KeSwHeVo"
      },
      "source": [
        "autoencoder.fit(\n",
        "    x=noisy_train_data,\n",
        "    y=train_data,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_test_data, test_data),\n",
        "    callbacks=[tensorboard_callback],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLA6vmxwHweS"
      },
      "source": [
        "## Make Predictions\n",
        "\n",
        "Let's now predict on the noisy data and display the results of our autoencoder.\n",
        "Notice how the autoencoder does an amazing job at removing the noise from the\n",
        "input images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6cCFrD-HuwA"
      },
      "source": [
        "predictions = autoencoder.predict(noisy_test_data)\n",
        "display(noisy_test_data, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDRFtPwnGLcT"
      },
      "source": [
        "## Push Autoencoder to Hugging Face Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiTMsNpmIGOC"
      },
      "source": [
        "from huggingface_hub import push_to_hub_keras\n",
        "\n",
        "push_to_hub_keras(autoencoder, 'autoencoder-keras-tensorboard-demo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/autoencoder-keras-tensorboard-demo/\n",
        "\n",
        "# I'm doing the below line via the file browser! Uncomment if you want to do it programmatically\n",
        "# ! cp -r /content/logs .\n",
        "\n",
        "! git status"
      ],
      "metadata": {
        "id": "8ZQw-C0A3Z8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git add logs/\n",
        "! git commit -m \"add logs\"\n",
        "! git push -u origin main"
      ],
      "metadata": {
        "id": "YCuFocNB3qQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klODQdTVE6qe"
      },
      "source": [
        "## Reload from hub and make predictions!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9KK-zi5EPIS"
      },
      "source": [
        "from huggingface_hub import from_pretrained_keras\n",
        "\n",
        "# Make sure to replace 'nateraw' with the username you logged in + pushed your model with\n",
        "reloaded_model = from_pretrained_keras('nateraw/autoencoder-keras-mnist-demo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZQb2_8iEvS_"
      },
      "source": [
        "predictions = reloaded_model.predict(noisy_test_data)\n",
        "display(noisy_test_data, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}